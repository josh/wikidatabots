name: TMDB ETL

on:
  schedule:
    - cron: "0 8 * * *"
  workflow_dispatch:

jobs:
  export:
    runs-on: ubuntu-latest
    concurrency: tmdb_export_${{ matrix.type }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - type: "movie"
            export_name: "movie_ids"
          - type: "tv"
            export_name: "tv_series_ids"
          - type: "person"
            export_name: "person_ids"

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r <(grep -E 'pandas|pyarrow' requirements.txt)

      - name: Generate export filename
        id: export_filename
        run: |
          TODAY=$(date --date=today +'%m_%d_%Y')
          YESTERDAY=$(date --date=yesterday +'%m_%d_%Y')
          echo "today_filename=${EXPORT_NAME}_${TODAY}.json.gz" >>"$GITHUB_OUTPUT"
          echo "yesterday_filename=${EXPORT_NAME}_${YESTERDAY}.json.gz" >>"$GITHUB_OUTPUT"
        env:
          EXPORT_NAME: ${{ matrix.export_name }}

      - name: Download today's export
        id: curl_today_export
        continue-on-error: true
        run: |
          curl --fail --no-progress-meter "http://files.tmdb.org/p/exports/$FILENAME" --output "export.json.gz"
        env:
          FILENAME: ${{ steps.export_filename.outputs.today_filename }}

      - name: Download yesterdays's export
        id: curl_yesterday_export
        if: steps.curl_today_export.outcome == 'failure'
        run: |
          curl --fail --no-progress-meter "http://files.tmdb.org/p/exports/$FILENAME" --output "export.json.gz"
        env:
          FILENAME: ${{ steps.export_filename.outputs.yesterday_filename }}

      - name: Transform export data
        shell: python
        run: |
          import pandas as pd

          dtype = {
              "id": "int64",
              "adult": "boolean",
              "original_title": "string",
              "original_name": "string",
              "popularity": "float64",
              "video": "boolean",
          }
          df = pd.read_json("export.json.gz", dtype=dtype, lines=True)
          df["in_export"] = True
          size = df["id"].max() + 1
          df = df.set_index("id").reindex(pd.RangeIndex(0, size)).reset_index(names=["id"])
          df["in_export"] = df["in_export"].fillna(False)
          df.to_feather("export.arrow")

      - name: Print stats
        run: |
          python print_table_stats.py export.arrow

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.type }}-export
          path: |
            *.arrow
          retention-days: 3

      - name: Upload to S3
        run: |
          aws s3 cp "export.arrow" "s3://$BUCKET_NAME/tmdb/$TYPE/export.arrow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: wikidatabots
          AWS_DEFAULT_REGION: us-east-1
          TYPE: ${{ matrix.type }}

  changes:
    runs-on: ubuntu-latest
    concurrency: tmdb_changes_${{ matrix.type }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - type: "movie"
          - type: "tv"
          - type: "person"

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r <(grep -E 'pandas|pyarrow' requirements.txt)

      - name: Download from S3
        run: |
          aws s3 cp "s3://$BUCKET_NAME/tmdb/$TYPE/changes.arrow" "changes.arrow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: wikidatabots
          AWS_DEFAULT_REGION: us-east-1
          TYPE: ${{ matrix.type }}

      - name: Fetch recent TMDB changes
        shell: bash
        run: |
          curl_config() {
            for N in $(seq 0 6); do
              START_DATE=$(date --date="today -$N day" +%Y-%m-%d)
              END_DATE=$(date --date="today -$N day +1 day" +%Y-%m-%d)
              URL="https://api.themoviedb.org/3/$TYPE/changes?api_key=$TMDB_API_KEY&start_date=$START_DATE&end_date=$END_DATE"
              echo "url = \"$URL\""
              echo "output = \"$RUNNER_TEMP/changes/$START_DATE.json\""
            done
          }
          mkdir -p "$RUNNER_TEMP/changes/"
          curl_config | tee "$RUNNER_TEMP/curl_config.txt"
          curl --fail --no-progress-meter --config "$RUNNER_TEMP/curl_config.txt"
        env:
          TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
          TYPE: ${{ matrix.type }}

      - name: Append TMDB changes
        run: |
          python tmdb_append_changes.py changes.arrow "$RUNNER_TEMP/changes"

      - name: Print stats
        run: |
          python print_table_stats.py changes.arrow

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.type }}-changes-export
          path: |
            *.arrow
          retention-days: 3

      - name: Upload to S3
        run: |
          aws s3 cp "changes.arrow" "s3://$BUCKET_NAME/tmdb/${TYPE}/changes.arrow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: wikidatabots
          AWS_DEFAULT_REGION: us-east-1
          TYPE: ${{ matrix.type }}

  external_ids:
    needs: changes
    runs-on: ubuntu-latest
    concurrency: tmdb_external_ids_${{ matrix.type }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - type: "movie"
          - type: "tv"
          - type: "person"

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Download from S3
        run: |
          aws s3 cp "s3://$BUCKET_NAME/tmdb/$TYPE/changes.arrow" "changes.arrow"
          aws s3 cp "s3://$BUCKET_NAME/tmdb/$TYPE/external_ids.arrow" "external_ids.arrow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: wikidatabots
          AWS_DEFAULT_REGION: us-east-1
          TYPE: ${{ matrix.type }}

      - name: Print stats
        run: |
          python print_table_stats.py external_ids.arrow

      - name: Get changed IDs
        id: tmdb_external_ids_outdated
        run: |
          python tmdb_external_ids_outdated.py external_ids.arrow changes.arrow >"$RUNNER_TEMP/changed_ids.txt"
          count=$(wc -l <"$RUNNER_TEMP/changed_ids.txt")
          echo "count=$count" | tee --append "$GITHUB_OUTPUT"

      - name: Generate changed curl config
        id: curl_config
        shell: bash
        run: |
          curl_config() {
            while read -r ID; do
              URL="https://api.themoviedb.org/3/$TYPE/$ID/external_ids?api_key=$TMDB_API_KEY"
              echo "url = \"$URL\""
              echo "output = \"$RUNNER_TEMP/external_ids/$ID.json\""
            done
          }
          mkdir -p "$RUNNER_TEMP/external_ids/"
          curl_config <"$RUNNER_TEMP/changed_ids.txt" | tee "$RUNNER_TEMP/curl_config.txt"
        env:
          TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
          TYPE: ${{ matrix.type }}

      - name: Fetch changed TMDB external IDs
        if: steps.tmdb_external_ids_outdated.outputs.count > 0
        run: |
          curl --no-progress-meter --config "$RUNNER_TEMP/curl_config.txt"

      - name: Run script
        run: |
          python tmdb_update_external_ids.py "external_ids.arrow" "$RUNNER_TEMP/external_ids"
        env:
          TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}

      - name: Print stats
        run: |
          python print_table_stats.py external_ids.arrow

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.type }}-external_ids-export
          path: |
            *.arrow
          retention-days: 3

      - name: Upload to S3
        run: |
          aws s3 cp "external_ids.arrow" "s3://$BUCKET_NAME/tmdb/${TYPE}/external_ids.arrow"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BUCKET_NAME: wikidatabots
          AWS_DEFAULT_REGION: us-east-1
          TYPE: ${{ matrix.type }}
