name: Apple TV ETL

on:
  schedule:
    - cron: "0 16 * * 1"
    - cron: "0 0,8,16 * * *"
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  sitemap:
    runs-on: ubuntu-latest
    if: github.event.schedule == "0 16 * * 1"

    strategy:
      fail-fast: false
      matrix:
        include:
          - type: "episode"
          - type: "movie"
          - type: "show"

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1-node16
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: us-east-1

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Set Python path
        run: |
          echo "PYTHONPATH=$GITHUB_WORKSPACE" >>"$GITHUB_ENV"

      - name: Load cache
        uses: actions/cache@v3
        with:
          path: .cache/
          key: cache-${{ github.job }}-${{ matrix.type }}-${{ github.run_id }}
          restore-keys: |
            cache-${{ github.job }}-${{ matrix.type }}-

      - name: Fetch sitemaps
        shell: python
        run: |
          import os

          from appletv_etl import cleaned_sitemap

          cleaned_sitemap(type=os.environ["TYPE"]).to_feather("sitemap_changes.arrow")
        env:
          TYPE: ${{ matrix.type }}

      - name: Print stats
        run: |
          python print_table_stats.py sitemap_changes.arrow

      - name: Download from S3
        run: |
          aws s3 cp "s3://$BUCKET_NAME/appletv/${TYPE}/sitemap.arrow" "sitemap.arrow"
          cp sitemap.arrow sitemap.arrow~
        env:
          BUCKET_NAME: wikidatabots
          TYPE: ${{ matrix.type }}

      - name: Join sitemap changes
        shell: python
        run: |
          import pandas as pd

          from appletv_etl import append_sitemap_changes

          df1 = pd.read_feather("sitemap.arrow")
          df2 = pd.read_feather("sitemap_changes.arrow")
          df3 = append_sitemap_changes(df1, df2)
          df3.to_feather("sitemap.arrow")

      - name: Print stats
        run: |
          python print_table_stats.py sitemap.arrow

      - name: Print diff
        run: |
          python print_table_diff.py sitemap.arrow~ sitemap.arrow loc

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.type }}-sitemap
          path: |
            *.arrow
          retention-days: 30

      - name: Upload to S3
        run: |
          aws s3 cp "sitemap.arrow" "s3://$BUCKET_NAME/appletv/${TYPE}/sitemap.arrow"
        env:
          BUCKET_NAME: wikidatabots
          TYPE: ${{ matrix.type }}

  jsonld:
    runs-on: ubuntu-latest
    if: github.event.schedule == "0 0,8,16 * * *"

    strategy:
      fail-fast: false
      matrix:
        include:
          - type: "episode"
          - type: "movie"
          - type: "show"

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1-node16
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: us-east-1

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Set Python path
        run: |
          echo "PYTHONPATH=$GITHUB_WORKSPACE" >>"$GITHUB_ENV"

      - name: Download from S3
        run: |
          aws s3 cp "s3://$BUCKET_NAME/appletv/${TYPE}/sitemap.arrow" "sitemap.arrow"
          aws s3 cp "s3://$BUCKET_NAME/appletv/${TYPE}/jsonld.arrow" "jsonld.arrow"
          cp jsonld.arrow jsonld.arrow~
        env:
          BUCKET_NAME: wikidatabots
          TYPE: ${{ matrix.type }}

      - name: Run script
        shell: python
        run: |
          import pandas as pd

          from appletv_etl import append_jsonld_changes

          sitemap_df = pd.read_feather("sitemap.arrow")
          jsonld_df = pd.read_feather("jsonld.arrow")
          jsonld_df = append_jsonld_changes(sitemap_df, jsonld_df, limit=5000)
          jsonld_df.to_feather("jsonld.arrow")

      - name: Print stats
        run: |
          python print_table_stats.py jsonld.arrow

      - name: Print diff
        run: |
          python print_table_diff.py jsonld.arrow~ jsonld.arrow loc

      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.type }}-jsonld
          path: |
            *.arrow
          retention-days: 30

      - name: Upload to S3
        run: |
          aws s3 cp "jsonld.arrow" "s3://$BUCKET_NAME/appletv/${TYPE}/jsonld.arrow"
        env:
          BUCKET_NAME: wikidatabots
          TYPE: ${{ matrix.type }}
